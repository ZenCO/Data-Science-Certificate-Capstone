---
title: "Twitter Capstone"
author: "Chase Smith"
date: "7/24/2019"
output:
  html_document: default
---

### For 07/31/19

Talking to Frank helped me realize that while I am an expert an Excel and data overall.  All of that helps me be a pretty darned good data scientist.  My EDA is pretty spot on.

I need to integrate the code that Scott Wrote.  I plan to work on that this weekend.

But here is what I need to finish my EDA.  I need to be able to chunk in the time frames.  I am thinking maybe in 2 hour increments.  That way I can show which time frames are most effective.

Also to Scott.  I realize my capstone project is geared towards small businesses.  And small business needs are very different than medium to large businesses.

I listened to the story about the guy who charged a lot more and provided a lot less.  And that's a AMAZING take away.

Small business people are pretty darned smart.  They worked their butts off to get to where they are.

My project is geared towards them.  Their most important need is to feel good about their business.  Yes, I am going to skew the data gently.  But I want a small business owner to see EVERYTHING they did well.  That is something they will buy into.

Then I can build a roadmap to improving their business.  Small businesses don't want the answer.  They want to know HOW to improve.  So I learned the lesson you shared... And I want to build a simple but obtainable roadmap to success.

If I run into a problem that needs a world class data analyst.. I know how to reach you and Frank.

But for now... most small businesses seriously need just amazing EDA.  And also some encouraging words and a small blueprint to success.

Now with that in mind, I want to further work on my capstone project.  I need it to be as clean and pretty as possible.

Because this is my business.  

### Business Objective

I am using R to fully explore the data available from Twitter to help a small business understand how to be more effective in their outreach.  I am using statistical analysis and Natural Language Programming to accomplish this.

### High Level Summary

I am using one of my own Twitter Accounts in order to explore the data available to any small business.  Cool, right?


### NECESSARY LIBRARIES
```{r}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("tidytext")
library("scales")
library("wordcloud")
library("reshape2")
data("stop_words")

```


#Exploratory Data Analysis
```{r}
raw_dat = read_csv('TwitterData.csv')
summary(raw_dat)
```

## Exploratory Data Analysis
```{r}


raw_dat = raw_dat %>%
select(id = `Tweet id`, TweetText = 'Tweet text', 'time', 'impressions', 'engagements', 'retweets', 'replies', 'likes')

summary(raw_dat)
  
```

```{r}
raw_dat = raw_dat %>%
  mutate(effective = if_else(engagements > 0,
                          "yes",
                          if_else(impressions > 300,
                                  "yes",
                                  "no")))
summary(raw_dat)

```


```{r}
dat = raw_dat %>%
  unnest_tokens(word, TweetText) %>%
  anti_join(stop_words, by = 'word')
```


```{r}
dat %>%
  count(word, sort = TRUE)
```


```{r}
dat = raw_dat %>%
  unnest_tokens(word, TweetText) %>%
  anti_join(stop_words, by = 'word') %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  filter(word != 'https') %>%
  filter(word != 't.co')
head(dat)
```

```{r}
dat %>%
  count(word, sort = TRUE) %>%
  summary()
```

### I need to figure out how to seperate all the @ data

```{r}
dat %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

### I NEED HELP HERE
###  THE LINE BELOW ISN"T WORKING!!!


```{r}
frequency = dat %>% 
  count(effective, word) %>%
  group_by(effective) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(effective, proportion) 
head(frequency)
```


```{r}
ggplot(frequency, aes(x = no, y = yes, color = abs(yes - no))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  theme(legend.position="none") +
  labs(y = "Word", x = NULL)
```


```{r}
cor.test(x = frequency$no, y = frequency$yes)
```

















### Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
