---
title: "Twitter Capstone"
author: "Chase Smith"
date: "9/5/2019"
output:
  html_document: default
---

### For 05/5/19

I want to explore the spreadsheet I was working on to better explain why I think the final column is important.  If it is, we can keep it.  I hear what Scott is saying that I am overfitting the model.  I think I agree with him.  But I think that my hunch is still accurate and I want to present this in class.

I didn't do work in R because I didn't want to waste my time if this is a rabbit hole.  But I put a BUNCH of thought into crafting my spreadsheet.

So that is what I am presenting.

### Business Objective
I am using R to fully explore the data available from Twitter to help a small business understand how to be more effective in their outreach.  I am using statistical analysis and Natural Language Programming to accomplish this.
### High Level Summary
I am using one of my own Twitter Accounts in order to explore the data available to any small business.  Cool, right?
### NECESSARY LIBRARIES
```{r setup, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("lubridate")
library("tidytext")
library("scales")
library("wordcloud")
library("reshape2")
data("stop_words")
```


## Exploratory Data Analysis
```{r data_load, warning=FALSE, message=FALSE}
raw_dat = read_csv('TwitterData.csv')
raw_dat = raw_dat %>%
select(id = `Tweet id`, TweetText = 'Tweet text', 'time', 'impressions', 'engagements', 'retweets', 'replies', 'likes')
raw_dat = raw_dat %>%
  mutate(year = year(time),
         month = month(time),
         day = day(time),
         hour = hour(time))
raw_dat = raw_dat %>%
  mutate(effective = if_else(engagements > 0,
                          "yes",
                          if_else(impressions > 300,
                                  "yes",
                                  "no"))) %>%
  tibble::rowid_to_column("localID")
summary(raw_dat)
```

```{r}
tweets_features = raw_dat %>%
  mutate(handle = if_else(str_detect(TweetText, '@'), TRUE, FALSE),
         hashtag = if_else(str_detect(TweetText, '#'), TRUE, FALSE),
  justtext = if_else(handle == TRUE, FALSE,
                             if_else(hashtag == TRUE, FALSE,
                                     TRUE))) 
  
tweets = raw_dat %>%
  unnest_tokens(words, TweetText, token = "tweets") %>%
  select(localID, id, effective, words) %>%
  mutate(handle = if_else(str_detect(words, '^@'), TRUE, FALSE),
         hashtag = if_else(str_detect(words, '^#'), TRUE, FALSE),
  justtext = if_else(handle == TRUE, FALSE,
                             if_else(hashtag == TRUE, FALSE,
                                     TRUE))) %>%
  mutate(text_type = if_else(handle == TRUE, "handle",
        if_else(justtext == TRUE, 'text','hashtag')))
head(tweets_features)
```

```{r}
# Hashtags
tweets %>%
  group_by(effective, text_type) %>%
  count(sort = TRUE) %>%
  ggplot(aes(x = effective, y = n, col = text_type, fill = text_type)) +
  geom_col()
```

```{r}
# Handles
tweets %>%
  group_by(effective, handle) %>%
  count(sort = TRUE) %>%
  ggplot(aes(x = handle, y = n)) +
  geom_col() + 
  facet_wrap(~effective)
```

```{r}
# Hashtags
tweets %>%
  group_by(effective, hashtag) %>%
  count(sort = TRUE) %>%
  ggplot(aes(x = hashtag, y = n)) +
  geom_col() + 
  facet_wrap(~effective)
```

```{r}
# JustText
tweets %>%
  group_by(effective, justtext) %>%
  count(sort = TRUE) %>%
  ggplot(aes(x = justtext, y = n)) +
  geom_col() + 
  facet_wrap(~effective)
```

```{r}
dat = tweets_features %>%
  select(localID, time, hashtag, handle, justtext, effective, TweetText) %>%
  unnest_tokens(word, TweetText) %>%
  anti_join(stop_words, by = 'word') %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  filter(word != 'https') %>%
  filter(word != 't.co') %>%
  filter(word != 't')
head(dat)
```

```{r}
tweets %>%
  count(words, sort = TRUE)
```

```{r}
dat %>%
  count(word, sort = TRUE) %>%
  summary()
```

```{r}
dat %>%
  filter(justtext == TRUE) %>%
  count(word, sort = TRUE) %>%
  filter(n > 5) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r}
frequency = dat %>% 
  filter(handle == FALSE) %>%
  count(effective, word) %>%
  group_by(effective) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(effective, proportion) 
frequency$no[is.na(frequency$no)] = 0
frequency$yes[is.na(frequency$yes)] = 0
frequency %>%
  arrange(-yes)
```

```{r}
frequency %>%
  filter(yes != 0 & no != 0 ) %>%
  ggplot(aes(x = no, y = yes, color = abs(yes - no))) +
    geom_abline(color = "gray40", lty = 2) +
    geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
    geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
    scale_x_log10(labels = percent_format()) +
    scale_y_log10(labels = percent_format()) +
    scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
    theme(legend.position="none") +
    labs(y = "Word", x = NULL)
```

```{r}
cor.test(x = frequency$no, y = frequency$yes)
```

# Saving Data for Excel Purposes

```{r}
frequency %>% write_csv('frequency.csv')
tweets %>% write_csv('tweets.csv')
tweets_features %>% write_csv('tweets_features.csv')
stop_words %>% write_csv('stop_words.csv')
raw_dat %>% write_csv('raw_dat.csv')
```








